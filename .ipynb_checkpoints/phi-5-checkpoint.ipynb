{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esyCj1A2SvI5"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdIg3cXaSvI-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to PyPhi!\n",
      "\n",
      "If you use PyPhi in your research, please cite the paper:\n",
      "\n",
      "  Mayner WGP, Marshall W, Albantakis L, Findlay G, Marchman R, Tononi G.\n",
      "  (2018). PyPhi: A toolbox for integrated information theory.\n",
      "  PLOS Computational Biology 14(7): e1006343.\n",
      "  https://doi.org/10.1371/journal.pcbi.1006343\n",
      "\n",
      "Documentation is available online (or with the built-in `help()` function):\n",
      "  https://pyphi.readthedocs.io\n",
      "\n",
      "To report issues, please use the issue tracker on the GitHub repository:\n",
      "  https://github.com/wmayner/pyphi\n",
      "\n",
      "For general discussion, you are welcome to join the pyphi-users group:\n",
      "  https://groups.google.com/forum/#!forum/pyphi-users\n",
      "\n",
      "To suppress this message, either:\n",
      "  - Set `WELCOME_OFF: true` in your `pyphi_config.yml` file, or\n",
      "  - Set the environment variable PYPHI_WELCOME_OFF to any value in your shell:\n",
      "        export PYPHI_WELCOME_OFF='yes'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNFeUhuOSvJA"
   },
   "outputs": [],
   "source": [
    "from itertools import chain,combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF5PTpEISvJC"
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OPX49EfSvJE"
   },
   "source": [
    "![title](phi_algorithm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KhY9DHhSvJF"
   },
   "outputs": [],
   "source": [
    "class phi():\n",
    "    def __init__(self,tpm,states=None):\n",
    "        self.tpm = tpm\n",
    "        self.num_nodes = int(np.log2(len(tpm)))\n",
    "        if states is None:\n",
    "            self.states = np.zeros((self.num_nodes))\n",
    "        else:\n",
    "            self.states = states\n",
    "        \n",
    "    # Converts a list of states to a row number, so that we can index the tpm\n",
    "    # input : list of states, Ex. [0,1,0,0]\n",
    "    # output : row number based on little endian notation, so index zero in list is least\n",
    "    #          significant bit and index n-1 is most significant bit. Ex. [0,1,0,0] -> 2\n",
    "    def state_to_index(self,states):\n",
    "        decimal = 0\n",
    "        for i,state in enumerate(states):\n",
    "            decimal += (2**i) * (state)\n",
    "        return decimal\n",
    "    \n",
    "    # Converts a row number from the tpm into a list of states\n",
    "    # input : row number, total number of states. Ex. (2, 4)\n",
    "    # output : list of states that row number represents. Ex. (2, 4) -> [0,1,0,0]\n",
    "    #          We include the number of states so that we know how many zeros to append at the end.\n",
    "    def index_to_state(self,index,num_states):\n",
    "        binary = bin(index)[2:]\n",
    "        states = []\n",
    "        for state in binary: # convert row to binary\n",
    "            states.append(int(state))\n",
    "        \n",
    "        states = np.flip(states) # flip to make little endian\n",
    "       \n",
    "        if (len(states) < num_states): \n",
    "            states = np.concatenate((states,np.zeros((num_states-len(states)),dtype=int)))\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    # Because they're conditional probability distributions, the rows need to sum to one\n",
    "    def normalize_rows(self,tpm):\n",
    "        return tpm/np.sum(tpm,1)[:, np.newaxis]\n",
    "    \n",
    "    # return the powerset of a list of nodes\n",
    "    def powerset(self,iterable):\n",
    "        \"powerset([1,2,3]) --> (1,) (2,) (3,) (1,2) (1,3) (2,3)\"\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(1,len(s)))\n",
    "    \n",
    "    # return the powerset of a list of nodes including full set\n",
    "    def powerset_all(self,iterable):\n",
    "        \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(0,len(s)+1))\n",
    "    \n",
    "    # returns the tensor product of two tpm (effect)\n",
    "    def tensor_product(self,t1,t2):\n",
    "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
    "        column = 0\n",
    "        for c2 in t2.T:\n",
    "            for c1 in t1.T:\n",
    "                tensor_product[:,column] = c1*c2\n",
    "                column+=1\n",
    "                \n",
    "        return tensor_product\n",
    "    \n",
    "    # This tensor product combines two effect repertoires t1 and t2, given a list of their nodes also\n",
    "    # This ensures that the nodes get ordered correctly even if the purview nodes of t1 are 'B' and the\n",
    "    # purview nodes of t2 are 'A,C'.\n",
    "    def tensor_product_ordered(self,t1,t1_nodes,t2,t2_nodes):\n",
    "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
    "        \n",
    "        # when we perform the tensor product we want to put the effect nodes in the correct order in the\n",
    "        # new tpm, but the purview might not be the full system of nodes, so we create a sorted list\n",
    "        # and index each purview node in the list\n",
    "        sorted_nodes = np.sort(t1_nodes + t2_nodes)\n",
    "        ordered_indexes = np.zeros((self.num_nodes),dtype=int)\n",
    "        order = 0\n",
    "        \n",
    "        for node in sorted_nodes:\n",
    "            ordered_indexes[node] = order\n",
    "            order+=1\n",
    "\n",
    "        columns = tensor_product.shape[1]\n",
    "        \n",
    "        # Fill the columns of the tpm one at a time\n",
    "        for column in range(columns):\n",
    "            # find the states of t1's nodes given the column we're currently filling\n",
    "            t1_state = self.index_to_state(column,int(np.log2(columns)))[ordered_indexes[t1_nodes]]\n",
    "            # do the same for t2's nodes\n",
    "            t2_state = self.index_to_state(column,int(np.log2(columns)))[ordered_indexes[t2_nodes]]\n",
    "            # Then fill the column with the correct column from t1 multiplied by the correct column from\n",
    "            # t2\n",
    "            tensor_product[:,column] = t1[:,self.state_to_index(t1_state)] * t2[:,self.state_to_index(t2_state)]\n",
    "            \n",
    "        return tensor_product\n",
    "        \n",
    "    \"\"\"\n",
    "    effect_repertoire :\n",
    "        input : mechanism (t nodes), purview (t+1 nodes)\n",
    "        algorithm : from original tpm find the tpm P(purview | mechanism)\n",
    "        output : repertoire for those nodes\n",
    "    \"\"\"    \n",
    "    def effect_repertoire(self,mechanism,purview):\n",
    "        # The effect repertoire captures the conditional transition probability of transitioning to each\n",
    "        # purview state, given the current mechanism state, so it needs to be of size\n",
    "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
    "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
    "        mechanism_effect_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
    "        \n",
    "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
    "        # only differ in the state of nodes not in the mechanism.\n",
    "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
    "        # to the correct row in the new mechanism repertoire\n",
    "        for row in range(self.tpm.shape[0]):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            mechanism_effect_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
    "        \n",
    "        # This is the final effect repertoire\n",
    "        effect_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
    "        \n",
    "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
    "        # only differ in the state of nodes not in the purview.\n",
    "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
    "        # to the correct column in the new effect repertoire\n",
    "        for column in range(self.tpm.shape[1]):\n",
    "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
    "            effect_repertoire[:,self.state_to_index(purview_state)] += mechanism_effect_repertoire[:,column]\n",
    "        \n",
    "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
    "        effect_repertoire = self.normalize_rows(effect_repertoire)\n",
    "        \n",
    "        # Now, we have to expand the effect_repertoire into the original state space which has all the \n",
    "        # possible current states at time t\n",
    "        expanded_effect_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
    "        \n",
    "        # This is done by mapping distributions in the effect_repertoire to each row in the expanded repertoire\n",
    "        # where the mechanism's state matches\n",
    "        for row in range(2**self.num_nodes):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            expanded_effect_repertoire[row,:] = effect_repertoire[self.state_to_index(mechanism_state),:]\n",
    "            \n",
    "        return expanded_effect_repertoire\n",
    "    \n",
    "    def effect_mip(self,system,purview):        \n",
    "        # We need to find the cut the makes the least difference to the tpm of the system,\n",
    "        # so we generate the original tpm first. We'll want to compare the original tpm\n",
    "        # with the tpm generated after making our cut to determine the cut that makes the\n",
    "        # least difference.\n",
    "        min_cut = None\n",
    "        cut_distance = float('inf')\n",
    "        full_tpm = self.effect_repertoire(system,purview)\n",
    "        \n",
    "        # We need to loop through two powersets to determine all the cuts for this particular \n",
    "        # system + purview pair. We need to loop through the system powerset and the purview powerset\n",
    "        # See factors.png below for an example.\n",
    "        \n",
    "        seen = set()\n",
    "        \n",
    "        for system_subset in self.powerset_all(system):\n",
    "            \n",
    "            for purview_subset in self.powerset_all(purview):\n",
    "                \n",
    "                # We haven't already seen the complement of the subset and the length of both of the factors\n",
    "                # aren't zero\n",
    "                if system_subset not in seen and not (len(system_subset) == 0 and len(purview_subset) == 0):\n",
    "                    system_factor_1 = list(system_subset)\n",
    "                    purview_factor_1 = list(purview_subset)\n",
    "                    \n",
    "                    system_factor_2 = list(np.setdiff1d(system,system_subset))\n",
    "                    purview_factor_2 = list(np.setdiff1d(purview,purview_subset))\n",
    "                    \n",
    "                    tpm_1 = self.effect_repertoire(system_factor_1,purview_factor_1)\n",
    "                    tpm_2 = self.effect_repertoire(system_factor_2,purview_factor_2)\n",
    "                    \n",
    "                    cut_tpm = self.tensor_product_ordered(tpm_1,purview_factor_1,tpm_2,purview_factor_2)\n",
    "                    \n",
    "                    # assess the distance between the cut_tpm and the full_tpm\n",
    "                    new_cut_distance = stats.wasserstein_distance(full_tpm[self.state_to_index(self.states)],\n",
    "                                                         cut_tpm[self.state_to_index(self.states)])\n",
    "                    \n",
    "#                     print ((system_factor_1,purview_factor_1,system_factor_2,purview_factor_2),\" \",new_cut_distance)\n",
    "                    \n",
    "                    # update the distance with the lowest distance\n",
    "                    if new_cut_distance <= cut_distance:\n",
    "                        cut_distance = new_cut_distance\n",
    "                        min_cut = (system_factor_1,purview_factor_1,system_factor_2,purview_factor_2)\n",
    "            \n",
    "            # add the complement of the system_subset to the seen set to ensure we don't double count certain\n",
    "            # partitions\n",
    "            seen.add(tuple(np.setdiff1d(system,system_subset)))\n",
    "        \n",
    "        return cut_distance,min_cut\n",
    "    \n",
    "    # TODO: implement this. Right now it's not working when the purview is smaller than the full\n",
    "    # list of nodes because the tensor product assumes the second dimension will be the full length\n",
    "    # of all the states given all the nodes\n",
    "    def mie(self,system):\n",
    "        phi = float('-inf')\n",
    "        mie = None\n",
    "        for purview in self.powerset_all(np.arange(self.num_nodes)):\n",
    "            cut_distance,min_cut = self.effect_mip(system,list(purview))\n",
    "            if cut_distance > phi:\n",
    "                phi = cut_distance\n",
    "                mie = purview\n",
    "        return phi,mie\n",
    "    \n",
    "    def concept(self,system):\n",
    "        \n",
    "        effect_phi,mie = self.mie(system)\n",
    "        cause_phi,mic = self.mic(system) # to be implemented\n",
    "        \n",
    "        return (min(effect_phi,cause_phi),mic,mie)\n",
    "                        \n",
    "    \"\"\"    \n",
    "    concept :\n",
    "        input : list of nodes in system (in our case this will be the whole system)\n",
    "        \n",
    "        algorithm : min (mic(system),mie(system))\n",
    "        \n",
    "        output : phi value for that system\n",
    "    \"\"\"\n",
    "\n",
    "    def cause_repertoire(self,purview,mechanism):\n",
    "        # The cause repertoire captures the conditional transition probability of transitioning to each\n",
    "        # purview state, given the current mechanism state, so it needs to be of size\n",
    "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
    "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
    "        mechanism_cause_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
    "        \n",
    "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
    "        # only differ in the state of nodes not in the mechanism.\n",
    "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
    "        # to the correct row in the new mechanism repertoire\n",
    "        for row in range(self.tpm.shape[0]):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            mechanism_cause_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
    "        \n",
    "        # This is the final cause repertoire\n",
    "        cause_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
    "        \n",
    "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
    "        # only differ in the state of nodes not in the purview.\n",
    "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
    "        # to the correct column in the new cause repertoire\n",
    "        for column in range(self.tpm.shape[1]):\n",
    "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
    "            cause_repertoire[:,self.state_to_index(purview_state)] += mechanism_cause_repertoire[:,column]\n",
    "        \n",
    "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
    "        cause_repertoire = self.normalize_rows(cause_repertoire)\n",
    "        \n",
    "        # Now, we have to expand the cause_repertoire into the original state space which has all the \n",
    "        # possible current states at time t\n",
    "        expanded_cause_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
    "        \n",
    "        # This is done by mapping distributions in the cause_repertoire to each row in the expanded repertoire\n",
    "        # where the mechanism's state matches\n",
    "        for row in range(2**self.num_nodes):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            expanded_cause_repertoire[row,:] = cause_repertoire[self.state_to_index(mechanism_state),:]\n",
    "            \n",
    "        # this ASSUMES there is only 1 thing in the purview, not sure what to do if there are more...\n",
    "        # drop the column that are not active in purview\n",
    "        # if len(purview) > 0:\n",
    "        #     return expanded_cause_repertoire[:,self.states[purview[0]]]\n",
    "        # else:\n",
    "        #     return expanded_cause_repertoire\n",
    "        \n",
    "        # the repertoire needs to be multiplies by the uniform distribution\n",
    "        # divide each thing by the number of items not in the purview\n",
    "        \n",
    "        num_alternate_states = (len(self.states) - len(purview)) * 2\n",
    "        if num_alternate_states != 0:\n",
    "            constant_factor = 1/num_alternate_states\n",
    "            if constant_factor != 0:\n",
    "                expanded_cause_repertoire = expanded_cause_repertoire * constant_factor\n",
    "#         print(expanded_cause_repertoire)\n",
    "        return expanded_cause_repertoire\n",
    "    \n",
    "    def cause_tensor_product(self,t1,t2,purview):\n",
    "        excluded_from_purview = set(range(len(starting_states))) - set(purview)\n",
    "        # multiply possibilities of cause_repertoire and things not in cause_repertoire\n",
    "        expanded_cause_repertoire_unsorted = np.array([])\n",
    "\n",
    "        for i in range(len(t2)):\n",
    "            expanded_cause_repertoire_unsorted = np.append(expanded_cause_repertoire_unsorted,t1 * t2[i])\n",
    "        \n",
    "        # make a copy of it\n",
    "        expanded_cause_repertoire = np.zeros((len(expanded_cause_repertoire_unsorted)))\n",
    "\n",
    "        # sort the copy\n",
    "        ordered = list(purview) + list(excluded_from_purview)\n",
    "        for i in range(len(expanded_cause_repertoire_unsorted)):\n",
    "            # make binary array\n",
    "            s = self.index_to_state(i,len(starting_states))\n",
    "            #re-order digits\n",
    "            reordered_s = np.full(len(s),9)\n",
    "            for j in range(len(ordered)):\n",
    "                reordered_s[j] = s[ordered[j]]\n",
    "            index = self.state_to_index(reordered_s)\n",
    "            expanded_cause_repertoire[i] = expanded_cause_repertoire_unsorted[index]\n",
    "        return expanded_cause_repertoire\n",
    "\n",
    "    def cause_mip(self,system,purview):        \n",
    "        # We need to find the cut the makes the least difference to the tpm of the system,\n",
    "        # so we generate the original tpm first. We'll want to compare the original tpm\n",
    "        # with the tpm generated after making our cut to determine the cut that makes the\n",
    "        # least difference.\n",
    "        min_cut = None\n",
    "        cut_distance = float('inf')\n",
    "        full_tpm = self.cause_repertoire(system,purview)\n",
    "        \n",
    "        # We need to loop through two powersets to determine all the cuts for this particular \n",
    "        # system + purview pair. We need to loop through the system powerset and the purview powerset\n",
    "        # See factors.png below for an example.\n",
    "        \n",
    "        seen = set()\n",
    "        \n",
    "        for system_subset in self.powerset_all(system):\n",
    "            \n",
    "            for purview_subset in self.powerset_all(purview):\n",
    "                \n",
    "                # We haven't already seen the complement of the subset and the length of both of the factors\n",
    "                # aren't zero\n",
    "                if system_subset not in seen and not (len(system_subset) == 0 and len(purview_subset) == 0):\n",
    "                    system_factor_1 = list(system_subset)\n",
    "                    purview_factor_1 = list(purview_subset)\n",
    "                    \n",
    "                    system_factor_2 = list(np.setdiff1d(system,system_subset))\n",
    "                    purview_factor_2 = list(np.setdiff1d(purview,purview_subset))\n",
    "                    \n",
    "                    tpm_1 = self.cause_repertoire(system_factor_1,purview_factor_1)\n",
    "                    tpm_2 = self.cause_repertoire(system_factor_2,purview_factor_2)\n",
    "                    \n",
    "                    cut_tpm = self.tensor_product_ordered(tpm_1,system_factor_1,tpm_2,system_factor_2)\n",
    "                    # assess the distance between the cut_tpm and the full_tpm\n",
    "                    new_cut_distance = stats.wasserstein_distance(full_tpm[self.state_to_index(self.states)],\n",
    "                                                         cut_tpm[self.state_to_index(self.states)])\n",
    "                    \n",
    "#                     print ((system_factor_1,purview_factor_1,system_factor_2,purview_factor_2),\" \",new_cut_distance)\n",
    "                    \n",
    "                    # update the distance with the lowest distance\n",
    "                    if new_cut_distance <= cut_distance:\n",
    "                        cut_distance = new_cut_distance\n",
    "                        min_cut = (system_factor_1,purview_factor_1,system_factor_2,purview_factor_2)\n",
    "            \n",
    "            # add the complement of the system_subset to the seen set to ensure we don't double count certain\n",
    "            # partitions\n",
    "            seen.add(tuple(np.setdiff1d(system,system_subset)))\n",
    "        \n",
    "        return cut_distance,min_cut\n",
    "\n",
    "    def mic(self,system):\n",
    "        phi = float('-inf')\n",
    "        mic = None\n",
    "        for purview in self.powerset_all(np.arange(self.num_nodes)):\n",
    "            cut_distance,min_cut = self.cause_mip(system,list(purview))\n",
    "            print(str(cut_distance) + ' ' + str(min_cut) + ' ' + str(purview))\n",
    "            if cut_distance >= phi and cut_distance != float(\"inf\"):\n",
    "                phi = cut_distance\n",
    "                mic = purview\n",
    "        return phi,mic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VksUWg_QSvJH"
   },
   "source": [
    "![title](factors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdL3m-AlSvJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.181640625 ([2], [], [0, 1], []) ()\n",
      "0.21354166666666669 ([1], [0], [0, 2], []) (0,)\n",
      "0.21354166666666669 ([1], [], [0, 2], [1]) (1,)\n",
      "0.181640625 ([2], [], [0, 1], [2]) (2,)\n",
      "0.24479166666666666 ([1], [], [0, 2], [0, 1]) (0, 1)\n",
      "0.18229166666666669 ([1], [], [0, 2], [0, 2]) (0, 2)\n",
      "0.2421875 ([2], [], [0, 1], [1, 2]) (1, 2)\n",
      "0.24652777777777776 ([1], [2], [0, 2], [0, 1]) (0, 1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:281: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24652777777777776, (0, 1, 2))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = phi(np.array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=int),[1,0,0])\n",
    "test.mic([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "tvxEo4A8SvJJ",
    "outputId": "c02ac7ee-f838-48f5-afdb-72ca3da9de7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = test.cause_repertoire([2],[1,2])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WErRqXUvSvJM",
    "outputId": "c283737c-c0d2-4221-c3aa-eeca164b7bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, ([], [2], [2], [1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.effect_mip([2],[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kr35Pbk5yIPb",
    "outputId": "932f17b6-05cb-40f4-af24-6c1613658434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "[2.66666667]\n",
      "[2. 2.]\n",
      "[2.66666667]\n",
      "[2. 2.]\n",
      "[2.66666667]\n",
      "[2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1875, ([], [1, 2], [2], []))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cause_mip([2],[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0yrAOoHSvJO",
    "outputId": "147f9252-8060-4dad-9df6-46a6b88f02ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.125, (0, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mie([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "jJAL-qP5SvJQ",
    "outputId": "c24e11c6-976a-44c0-d735-0755fe89d399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ([2], [], [0, 1], []) ()\n",
      "0.0625 ([2], [0], [0, 1], []) (0,)\n",
      "0.0625 ([2], [1], [0, 1], []) (1,)\n",
      "0.0 ([2], [], [0, 1], [2]) (2,)\n",
      "0.0625 ([2], [0, 1], [0, 1], []) (0, 1)\n",
      "0.0625 ([1], [0, 2], [0, 2], []) (0, 2)\n",
      "0.0 ([2], [], [0, 1], [1, 2]) (1, 2)\n",
      "0.0625 ([1], [], [0, 2], [0, 1, 2]) (0, 1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0625, (0, 1, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mic([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpm = np.array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=int)\n",
    "\n",
    "network = pyphi.Network(tpm)\n",
    "state = (1,0,0)\n",
    "\n",
    "node_indices = (0, 1, 2)\n",
    "subsystem = pyphi.Subsystem(network, state, node_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25, 0.25],\n",
       "        [0.25, 0.25]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsystem.cause_repertoire((2,),(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625],\n",
       "       [0.0625, 0.0625]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cause_repertoire([2],[1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.125, 0.125],\n",
       "        [0.125, 0.125]],\n",
       "\n",
       "       [[0.125, 0.125],\n",
       "        [0.125, 0.125]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsystem.expand_cause_repertoire(subsystem.cause_repertoire((2,),(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maximally-irreducible cause\n",
       "  φ = 1/2\n",
       "  Mechanism: [n0, n1, n2]\n",
       "  Purview = [n0, n1, n2]\n",
       "  Direction: CAUSE\n",
       "  MIP:\n",
       "    n0     n1,n2  \n",
       "    ─── ✕ ────────\n",
       "     ∅    n0,n1,n2\n",
       "  Repertoire:\n",
       "    ┌───────────────┐\n",
       "    │  S     Pr(S)  │\n",
       "    │ ╴╴╴╴╴╴╴╴╴╴╴╴╴ │\n",
       "    │ 000    0      │\n",
       "    │ 100    0      │\n",
       "    │ 010    0      │\n",
       "    │ 110    1/2    │\n",
       "    │ 001    1/2    │\n",
       "    │ 101    0      │\n",
       "    │ 011    0      │\n",
       "    │ 111    0      │\n",
       "    └───────────────┘\n",
       "  Partitioned repertoire:\n",
       "    ┌───────────────┐\n",
       "    │  S     Pr(S)  │\n",
       "    │ ╴╴╴╴╴╴╴╴╴╴╴╴╴ │\n",
       "    │ 000    1/3    │\n",
       "    │ 100    0      │\n",
       "    │ 010    0      │\n",
       "    │ 110    1/3    │\n",
       "    │ 001    1/3    │\n",
       "    │ 101    0      │\n",
       "    │ 011    0      │\n",
       "    │ 111    0      │\n",
       "    └───────────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsystem.mic((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "phi-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
