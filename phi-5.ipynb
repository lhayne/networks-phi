{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "phi-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esyCj1A2SvI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdIg3cXaSvI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyphi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNFeUhuOSvJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain,combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF5PTpEISvJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OPX49EfSvJE",
        "colab_type": "text"
      },
      "source": [
        "![title](phi_algorithm.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhY9DHhSvJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class phi():\n",
        "    def __init__(self,tpm,states=None):\n",
        "        self.tpm = tpm\n",
        "        self.num_nodes = int(np.log2(len(tpm)))\n",
        "        if states is None:\n",
        "            self.states = np.zeros((self.num_nodes))\n",
        "        else:\n",
        "            self.states = states\n",
        "        \n",
        "    # Converts a list of states to a row number, so that we can index the tpm\n",
        "    # input : list of states, Ex. [0,1,0,0]\n",
        "    # output : row number based on little endian notation, so index zero in list is least\n",
        "    #          significant bit and index n-1 is most significant bit. Ex. [0,1,0,0] -> 2\n",
        "    def state_to_index(self,states):\n",
        "        decimal = 0\n",
        "        for i,state in enumerate(states):\n",
        "            decimal += (2**i) * (state)\n",
        "        return decimal\n",
        "    \n",
        "    # Converts a row number from the tpm into a list of states\n",
        "    # input : row number, total number of states. Ex. (2, 4)\n",
        "    # output : list of states that row number represents. Ex. (2, 4) -> [0,1,0,0]\n",
        "    #          We include the number of states so that we know how many zeros to append at the end.\n",
        "    def index_to_state(self,index,num_states):\n",
        "        binary = bin(index)[2:]\n",
        "        states = []\n",
        "        for state in binary: # convert row to binary\n",
        "            states.append(int(state))\n",
        "        \n",
        "        states = np.flip(states) # flip to make little endian\n",
        "       \n",
        "        if (len(states) < num_states): \n",
        "            states = np.concatenate((states,np.zeros((num_states-len(states)),dtype=int)))\n",
        "            \n",
        "        return states\n",
        "    \n",
        "    # Because they're conditional probability distributions, the rows need to sum to one\n",
        "    def normalize_rows(self,tpm):\n",
        "        return tpm/np.sum(tpm,1)[:, np.newaxis]\n",
        "    \n",
        "    # return the powerset of a list of nodes\n",
        "    def powerset(self,iterable):\n",
        "        \"powerset([1,2,3]) --> (1,) (2,) (3,) (1,2) (1,3) (2,3)\"\n",
        "        s = list(iterable)\n",
        "        return chain.from_iterable(combinations(s, r) for r in range(1,len(s)))\n",
        "    \n",
        "    # return the powerset of a list of nodes including full set\n",
        "    def powerset_all(self,iterable):\n",
        "        \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "        s = list(iterable)\n",
        "        return chain.from_iterable(combinations(s, r) for r in range(0,len(s)+1))\n",
        "    \n",
        "    # returns the tensor product of two tpm (effect)\n",
        "    def tensor_product(self,t1,t2):\n",
        "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
        "        column = 0\n",
        "        for c2 in t2.T:\n",
        "            for c1 in t1.T:\n",
        "                tensor_product[:,column] = c1*c2\n",
        "                column+=1\n",
        "                \n",
        "        return tensor_product\n",
        "    \n",
        "    # This tensor product combines two effect repertoires t1 and t2, given a list of their nodes also\n",
        "    # This ensures that the nodes get ordered correctly even if the purview nodes of t1 are 'B' and the\n",
        "    # purview nodes of t2 are 'A,C'.\n",
        "    def tensor_product_ordered(self,t1,t1_nodes,t2,t2_nodes):\n",
        "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
        "        \n",
        "        # when we perform the tensor product we want to put the effect nodes in the correct order in the\n",
        "        # new tpm, but the purview might not be the full system of nodes, so we create a sorted list\n",
        "        # and index each purview node in the list\n",
        "        sorted_nodes = np.sort(t1_nodes + t2_nodes)\n",
        "        ordered_indexes = np.zeros((self.num_nodes),dtype=int)\n",
        "        order = 0\n",
        "        \n",
        "        for node in sorted_nodes:\n",
        "            ordered_indexes[node] = order\n",
        "            order+=1\n",
        "\n",
        "        columns = tensor_product.shape[1]\n",
        "        \n",
        "        # Fill the columns of the tpm one at a time\n",
        "        for column in range(columns):\n",
        "            # find the states of t1's nodes given the column we're currently filling\n",
        "            t1_state = self.index_to_state(column,int(np.log2(columns)))[ordered_indexes[t1_nodes]]\n",
        "            # do the same for t2's nodes\n",
        "            t2_state = self.index_to_state(column,int(np.log2(columns)))[ordered_indexes[t2_nodes]]\n",
        "            # Then fill the column with the correct column from t1 multiplied by the correct column from\n",
        "            # t2\n",
        "            tensor_product[:,column] = t1[:,self.state_to_index(t1_state)] * t2[:,self.state_to_index(t2_state)]\n",
        "            \n",
        "        return tensor_product\n",
        "        \n",
        "    \"\"\"\n",
        "    effect_repertoire :\n",
        "        input : mechanism (t nodes), purview (t+1 nodes)\n",
        "        algorithm : from original tpm find the tpm P(purview | mechanism)\n",
        "        output : repertoire for those nodes\n",
        "    \"\"\"    \n",
        "    def effect_repertoire(self,mechanism,purview):\n",
        "        # The effect repertoire captures the conditional transition probability of transitioning to each\n",
        "        # purview state, given the current mechanism state, so it needs to be of size\n",
        "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
        "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
        "        mechanism_effect_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
        "        \n",
        "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
        "        # only differ in the state of nodes not in the mechanism.\n",
        "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
        "        # to the correct row in the new mechanism repertoire\n",
        "        for row in range(self.tpm.shape[0]):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            mechanism_effect_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
        "        \n",
        "        # This is the final effect repertoire\n",
        "        effect_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
        "        \n",
        "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
        "        # only differ in the state of nodes not in the purview.\n",
        "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
        "        # to the correct column in the new effect repertoire\n",
        "        for column in range(self.tpm.shape[1]):\n",
        "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
        "            effect_repertoire[:,self.state_to_index(purview_state)] += mechanism_effect_repertoire[:,column]\n",
        "        \n",
        "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
        "        effect_repertoire = self.normalize_rows(effect_repertoire)\n",
        "        \n",
        "        # Now, we have to expand the effect_repertoire into the original state space which has all the \n",
        "        # possible current states at time t\n",
        "        expanded_effect_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
        "        \n",
        "        # This is done by mapping distributions in the effect_repertoire to each row in the expanded repertoire\n",
        "        # where the mechanism's state matches\n",
        "        for row in range(2**self.num_nodes):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            expanded_effect_repertoire[row,:] = effect_repertoire[self.state_to_index(mechanism_state),:]\n",
        "            \n",
        "        return expanded_effect_repertoire\n",
        "    \n",
        "    def effect_mip(self,system,purview):        \n",
        "        # We need to find the cut the makes the least difference to the tpm of the system,\n",
        "        # so we generate the original tpm first. We'll want to compare the original tpm\n",
        "        # with the tpm generated after making our cut to determine the cut that makes the\n",
        "        # least difference.\n",
        "        min_cut = None\n",
        "        cut_distance = float('inf')\n",
        "        full_tpm = self.effect_repertoire(system,purview)\n",
        "        \n",
        "        # We need to loop through two powersets to determine all the cuts for this particular \n",
        "        # system + purview pair. We need to loop through the system powerset and the purview powerset\n",
        "        # See factors.png below for an example.\n",
        "        \n",
        "        seen = set()\n",
        "        \n",
        "        for system_subset in self.powerset_all(system):\n",
        "            \n",
        "            for purview_subset in self.powerset_all(purview):\n",
        "                \n",
        "                # We haven't already seen the complement of the subset and the length of both of the factors\n",
        "                # aren't zero\n",
        "                if system_subset not in seen and not (len(system_subset) == 0 and len(purview_subset) == 0):\n",
        "                    system_factor_1 = list(system_subset)\n",
        "                    purview_factor_1 = list(purview_subset)\n",
        "                    \n",
        "                    system_factor_2 = list(np.setdiff1d(system,system_subset))\n",
        "                    purview_factor_2 = list(np.setdiff1d(purview,purview_subset))\n",
        "                    \n",
        "                    tpm_1 = self.effect_repertoire(system_factor_1,purview_factor_1)\n",
        "                    tpm_2 = self.effect_repertoire(system_factor_2,purview_factor_2)\n",
        "                    \n",
        "                    cut_tpm = self.tensor_product_ordered(tpm_1,purview_factor_1,tpm_2,purview_factor_2)\n",
        "                    \n",
        "                    # assess the distance between the cut_tpm and the full_tpm\n",
        "                    new_cut_distance = stats.wasserstein_distance(full_tpm[self.state_to_index(self.states)],\n",
        "                                                         cut_tpm[self.state_to_index(self.states)])\n",
        "                    \n",
        "#                     print ((system_factor_1,purview_factor_1,system_factor_2,purview_factor_2),\" \",new_cut_distance)\n",
        "                    \n",
        "                    # update the distance with the lowest distance\n",
        "                    if new_cut_distance <= cut_distance:\n",
        "                        cut_distance = new_cut_distance\n",
        "                        min_cut = (system_factor_1,purview_factor_1,system_factor_2,purview_factor_2)\n",
        "            \n",
        "            # add the complement of the system_subset to the seen set to ensure we don't double count certain\n",
        "            # partitions\n",
        "            seen.add(tuple(np.setdiff1d(system,system_subset)))\n",
        "        \n",
        "        return cut_distance,min_cut\n",
        "    \n",
        "    # TODO: implement this. Right now it's not working when the purview is smaller than the full\n",
        "    # list of nodes because the tensor product assumes the second dimension will be the full length\n",
        "    # of all the states given all the nodes\n",
        "    def mie(self,system):\n",
        "        phi = float('-inf')\n",
        "        mie = None\n",
        "        for purview in self.powerset_all(np.arange(self.num_nodes)):\n",
        "            cut_distance,min_cut = self.effect_mip(system,list(purview))\n",
        "            if cut_distance > phi:\n",
        "                phi = cut_distance\n",
        "                mie = purview\n",
        "        return phi,mie\n",
        "    \n",
        "    def concept(self,system):\n",
        "        \n",
        "        effect_phi,mie = self.mie(system)\n",
        "        cause_phi,mic = self.mic(system) # to be implemented\n",
        "        \n",
        "        return (min(effect_phi,cause_phi),mic,mie)\n",
        "                        \n",
        "    \"\"\"    \n",
        "    concept :\n",
        "        input : list of nodes in system (in our case this will be the whole system)\n",
        "        \n",
        "        algorithm : min (mic(system),mie(system))\n",
        "        \n",
        "        output : phi value for that system\n",
        "    \"\"\"\n",
        "\n",
        "    def cause_repertoire(self,purview,mechanism):\n",
        "        # The cause repertoire captures the conditional transition probability of transitioning to each\n",
        "        # purview state, given the current mechanism state, so it needs to be of size\n",
        "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
        "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
        "        mechanism_cause_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
        "        \n",
        "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
        "        # only differ in the state of nodes not in the mechanism.\n",
        "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
        "        # to the correct row in the new mechanism repertoire\n",
        "        for row in range(self.tpm.shape[0]):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            mechanism_cause_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
        "        \n",
        "        # This is the final cause repertoire\n",
        "        cause_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
        "        \n",
        "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
        "        # only differ in the state of nodes not in the purview.\n",
        "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
        "        # to the correct column in the new cause repertoire\n",
        "        for column in range(self.tpm.shape[1]):\n",
        "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
        "            cause_repertoire[:,self.state_to_index(purview_state)] += mechanism_cause_repertoire[:,column]\n",
        "        \n",
        "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
        "        cause_repertoire = self.normalize_rows(cause_repertoire)\n",
        "        \n",
        "        # Now, we have to expand the cause_repertoire into the original state space which has all the \n",
        "        # possible current states at time t\n",
        "        expanded_cause_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
        "        \n",
        "        # This is done by mapping distributions in the cause_repertoire to each row in the expanded repertoire\n",
        "        # where the mechanism's state matches\n",
        "        for row in range(2**self.num_nodes):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            expanded_cause_repertoire[row,:] = cause_repertoire[self.state_to_index(mechanism_state),:]\n",
        "            \n",
        "        # this ASSUMES there is only 1 thing in the purview, not sure what to do if there are more...\n",
        "        # drop the column that are not active in purview\n",
        "        # if len(purview) > 0:\n",
        "        #     return expanded_cause_repertoire[:,self.states[purview[0]]]\n",
        "        # else:\n",
        "        #     return expanded_cause_repertoire\n",
        "        return expanded_cause_repertoire\n",
        "    \n",
        "    def cause_tensor_product(self,t1,t2,purview):\n",
        "        excluded_from_purview = set(range(len(starting_states))) - set(purview)\n",
        "        # multiply possibilities of cause_repertoire and things not in cause_repertoire\n",
        "        expanded_cause_repertoire_unsorted = np.array([])\n",
        "\n",
        "        for i in range(len(t2)):\n",
        "            expanded_cause_repertoire_unsorted = np.append(expanded_cause_repertoire_unsorted,t1 * t2[i])\n",
        "        \n",
        "        # make a copy of it\n",
        "        expanded_cause_repertoire = np.zeros((len(expanded_cause_repertoire_unsorted)))\n",
        "\n",
        "        # sort the copy\n",
        "        ordered = list(purview) + list(excluded_from_purview)\n",
        "        for i in range(len(expanded_cause_repertoire_unsorted)):\n",
        "            # make binary array\n",
        "            s = self.index_to_state(i,len(starting_states))\n",
        "            #re-order digits\n",
        "            reordered_s = np.full(len(s),9)\n",
        "            for j in range(len(ordered)):\n",
        "                reordered_s[j] = s[ordered[j]]\n",
        "            index = self.state_to_index(reordered_s)\n",
        "            expanded_cause_repertoire[i] = expanded_cause_repertoire_unsorted[index]\n",
        "        return expanded_cause_repertoire\n",
        "\n",
        "    def cause_mip(self,system,purview):        \n",
        "        # We need to find the cut the makes the least difference to the tpm of the system,\n",
        "        # so we generate the original tpm first. We'll want to compare the original tpm\n",
        "        # with the tpm generated after making our cut to determine the cut that makes the\n",
        "        # least difference.\n",
        "        min_cut = None\n",
        "        cut_distance = float('inf')\n",
        "        full_tpm = self.cause_repertoire(system,purview)\n",
        "        \n",
        "        # We need to loop through two powersets to determine all the cuts for this particular \n",
        "        # system + purview pair. We need to loop through the system powerset and the purview powerset\n",
        "        # See factors.png below for an example.\n",
        "        \n",
        "        seen = set()\n",
        "        \n",
        "        for system_subset in self.powerset_all(system):\n",
        "            \n",
        "            for purview_subset in self.powerset_all(purview):\n",
        "                \n",
        "                # We haven't already seen the complement of the subset and the length of both of the factors\n",
        "                # aren't zero\n",
        "                if system_subset not in seen and not (len(system_subset) == 0 and len(purview_subset) == 0):\n",
        "                    system_factor_1 = list(system_subset)\n",
        "                    purview_factor_1 = list(purview_subset)\n",
        "                    \n",
        "                    system_factor_2 = list(np.setdiff1d(system,system_subset))\n",
        "                    purview_factor_2 = list(np.setdiff1d(purview,purview_subset))\n",
        "                    \n",
        "                    tpm_1 = self.cause_repertoire(system_factor_1,purview_factor_1)\n",
        "                    tpm_2 = self.cause_repertoire(system_factor_2,purview_factor_2)\n",
        "                    \n",
        "                    cut_tpm = self.tensor_product_ordered(tpm_1,system_factor_1,tpm_2,system_factor_2)\n",
        "                    # assess the distance between the cut_tpm and the full_tpm\n",
        "                    new_cut_distance = stats.wasserstein_distance(full_tpm[self.state_to_index(self.states)],\n",
        "                                                         cut_tpm[self.state_to_index(self.states)])\n",
        "                    \n",
        "#                     print ((system_factor_1,purview_factor_1,system_factor_2,purview_factor_2),\" \",new_cut_distance)\n",
        "                    \n",
        "                    # update the distance with the lowest distance\n",
        "                    if new_cut_distance <= cut_distance:\n",
        "                        cut_distance = new_cut_distance\n",
        "                        min_cut = (system_factor_1,purview_factor_1,system_factor_2,purview_factor_2)\n",
        "            \n",
        "            # add the complement of the system_subset to the seen set to ensure we don't double count certain\n",
        "            # partitions\n",
        "            seen.add(tuple(np.setdiff1d(system,system_subset)))\n",
        "        \n",
        "        return cut_distance,min_cut\n",
        "\n",
        "    def mic(self,system):\n",
        "        phi = float('-inf')\n",
        "        mic = None\n",
        "        for purview in self.powerset_all(np.arange(self.num_nodes)):\n",
        "            cut_distance,min_cut = self.cause_mip(system,list(purview))\n",
        "            print(str(cut_distance) + ' ' + str(min_cut) + ' ' + str(purview))\n",
        "            if cut_distance >= phi:\n",
        "                phi = cut_distance\n",
        "                mic = purview\n",
        "        return phi,mic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VksUWg_QSvJH",
        "colab_type": "text"
      },
      "source": [
        "![title](factors.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdL3m-AlSvJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = phi(np.array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 1., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 0., 0., 0., 1.],\n",
        "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "                   [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=int),[1,0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvxEo4A8SvJJ",
        "colab_type": "code",
        "outputId": "c02ac7ee-f838-48f5-afdb-72ca3da9de7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "t = test.cause_repertoire([2],[1,2])\n",
        "t"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5],\n",
              "       [0.5, 0.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om11TSatYFNc",
        "colab_type": "code",
        "outputId": "94abe9a4-d6a5-4555-88ea-fae4a5e1e5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "purview = [2]\n",
        "for i in purview:\n",
        "    if test.states[i]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WErRqXUvSvJM",
        "colab_type": "code",
        "outputId": "c283737c-c0d2-4221-c3aa-eeca164b7bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test.effect_mip([2],[1,2])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, ([], [2], [2], [1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr35Pbk5yIPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "932f17b6-05cb-40f4-af24-6c1613658434"
      },
      "source": [
        "test.cause_mip([2],[1,2])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, ([], [1, 2], [2], []))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0yrAOoHSvJO",
        "colab_type": "code",
        "outputId": "147f9252-8060-4dad-9df6-46a6b88f02ed",
        "colab": {}
      },
      "source": [
        "test.mie([0,1,2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.125, (0, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJAL-qP5SvJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c24e11c6-976a-44c0-d735-0755fe89d399"
      },
      "source": [
        "test.mic([0,1,2])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 ([2], [], [0, 1], []) ()\n",
            "0.0625 ([2], [0], [0, 1], []) (0,)\n",
            "0.0625 ([2], [1], [0, 1], []) (1,)\n",
            "0.0 ([2], [], [0, 1], [2]) (2,)\n",
            "0.0625 ([2], [0, 1], [0, 1], []) (0, 1)\n",
            "0.0625 ([1], [0, 2], [0, 2], []) (0, 2)\n",
            "0.0 ([2], [], [0, 1], [1, 2]) (1, 2)\n",
            "0.0625 ([1], [], [0, 2], [0, 1, 2]) (0, 1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0625, (0, 1, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}