{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](phi_algorithm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class phi():\n",
    "    def __init__(self,tpm):\n",
    "        self.tpm = tpm\n",
    "        self.num_nodes = int(np.log2(len(tpm)))\n",
    "        \n",
    "    # Converts a list of states to a row number, so that we can index the tpm\n",
    "    # input : list of states, Ex. [0,1,0,0]\n",
    "    # output : row number based on little endian notation, so index zero in list is least\n",
    "    #          significant bit and index n-1 is most significant bit. Ex. [0,1,0,0] -> 2\n",
    "    def state_to_index(self,states):\n",
    "        decimal = 0\n",
    "        for i,state in enumerate(states):\n",
    "            decimal += (2**i) * (state)\n",
    "        return decimal\n",
    "    \n",
    "    # Converts a row number from the tpm into a list of states\n",
    "    # input : row number, total number of states. Ex. (2, 4)\n",
    "    # output : list of states that row number represents. Ex. (2, 4) -> [0,1,0,0]\n",
    "    #          We include the number of states so that we know how many zeros to append at the end.\n",
    "    def index_to_state(self,index,num_states):\n",
    "        binary = bin(index)[2:]\n",
    "        states = []\n",
    "        for state in binary: # convert row to binary\n",
    "            states.append(int(state))\n",
    "        \n",
    "        states = np.flip(states) # flip to make little endian\n",
    "       \n",
    "        if (len(states) < num_states): \n",
    "            states = np.concatenate((states,np.zeros((num_states-len(states)),dtype=int)))\n",
    "            \n",
    "        return states\n",
    "    \n",
    "    # Because they're conditional probability distributions, the rows need to sum to one\n",
    "    def normalize_rows(self,tpm):\n",
    "        return tpm/np.sum(tpm,1)[:, np.newaxis]\n",
    "    \n",
    "    # return the powerset of a list of nodes\n",
    "    def powerset(self,iterable):\n",
    "        \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(1,len(s)+1))\n",
    "    \n",
    "    # returns the tensor product of two tpm (effect)\n",
    "    def tensor_product(self,t1,t2):\n",
    "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
    "        row = 0\n",
    "        for c2 in t2.T:\n",
    "            for c1 in t1.T:\n",
    "                tensor_product[:,row] = c1*c2\n",
    "                row+=1\n",
    "                \n",
    "        return tensor_product\n",
    "        \n",
    "    \"\"\"\n",
    "    effect_repertoire :\n",
    "        input : mechanism (t nodes), purview (t+1 nodes)\n",
    "        algorithm : from original tpm find the tpm P(purview | mechanism)\n",
    "        output : repertoire for those nodes\n",
    "    \"\"\"    \n",
    "    def effect_repertoire(self,mechanism,purview):\n",
    "        # The effect repertoire captures the conditional transition probability of transitioning to each\n",
    "        # purview state, given the current mechanism state, so it needs to be of size\n",
    "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
    "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
    "        mechanism_effect_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
    "        \n",
    "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
    "        # only differ in the state of nodes not in the mechanism.\n",
    "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
    "        # to the correct row in the new mechanism repertoire\n",
    "        for row in range(self.tpm.shape[0]):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            mechanism_effect_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
    "        \n",
    "        # This is the final effect repertoire\n",
    "        effect_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
    "        \n",
    "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
    "        # only differ in the state of nodes not in the purview.\n",
    "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
    "        # to the correct column in the new effect repertoire\n",
    "        for column in range(self.tpm.shape[1]):\n",
    "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
    "            effect_repertoire[:,self.state_to_index(purview_state)] += mechanism_effect_repertoire[:,column]\n",
    "        \n",
    "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
    "        effect_repertoire = self.normalize_rows(effect_repertoire)\n",
    "        \n",
    "        # Now, we have to expand the effect_repertoire into the original state space which has all the \n",
    "        # possible current states at time t\n",
    "        expanded_effect_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
    "        \n",
    "        # This is done by mapping distributions in the effect_repertoire to each row in the expanded repertoire\n",
    "        # where the mechanism's state matches\n",
    "        for row in range(2**self.num_nodes):\n",
    "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
    "            expanded_effect_repertoire[row,:] = effect_repertoire[self.state_to_index(mechanism_state),:]\n",
    "            \n",
    "        return expanded_effect_repertoire\n",
    "    \n",
    "    def effect_mip(self,system,purview):\n",
    "        pass\n",
    "        \"\"\"\n",
    "        for each possible partition of the pair (system + purview):\n",
    "            for each partitioned subset:\n",
    "                partitioned tpm = tensor multiply partitioned subset tpms \n",
    "                                    (effect_repertoire(part_system,part_purview))\n",
    "            calculate distance between partitioned tpm and effect_repertoire(system,purview)\n",
    "        return smallest distance\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    effect_mip : \n",
    "        input : system (t nodes) , purview (t+1 nodes)\n",
    "        \n",
    "        algorithm : for each possible partition of the pair (system + purview):\n",
    "                        for each partitioned subset:\n",
    "                            partitioned tpm = tensor multiply partitioned subset tpms \n",
    "                                                (effect_repertoire(part_system,part_purview))\n",
    "                        calculate distance between partitioned tpm and effect_repertoire(system,purview)\n",
    "                    return smallest distance\n",
    "                    \n",
    "        output : phi (distance between effect repertoire and minimum information partition repertoire)\n",
    "        \n",
    "    mie : \n",
    "        input : tpm for a specific system (in our case this is the entire system)\n",
    "        \n",
    "        algorithm : for each subset of nodes at t+1 of the system (call this a purview):\n",
    "                        call effect_mip(system, purview)\n",
    "                    return max effect_mip\n",
    "        \n",
    "        output : effect phi value\n",
    "                        \n",
    "        \n",
    "    concept :\n",
    "        input : list of nodes in system (in our case this will be the whole system)\n",
    "        \n",
    "        algorithm : min (mic(system),mie(system))\n",
    "        \n",
    "        output : phi value for that system\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = phi(np.array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                   [0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "                   [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.  0.5 0.  0.5]\n",
      " [0.  0.5 0.  0.5]\n",
      " [0.  0.5 0.  0.5]\n",
      " [0.  0.5 0.  0.5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  ],\n",
       "       [0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  ],\n",
       "       [0.  , 0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  ],\n",
       "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
       "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
       "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
       "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = test.tensor_product(test.effect_repertoire([1,2],[0]),test.effect_repertoire([2],[1]))\n",
    "print (p1)\n",
    "test.tensor_product(p1,test.effect_repertoire([1],[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
