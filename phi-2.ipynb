{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "phi-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycKtGjxyAQQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulkPUMylAQRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "09a235a8-cd0d-477f-80e8-e5c551595a39"
      },
      "source": [
        "import pyphi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e8e7b40cec2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyphi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyphi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlb_IbJeAQRF",
        "colab_type": "text"
      },
      "source": [
        "![title](phi_algorithm.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xptZ5Bv-AQRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class phi():\n",
        "    def __init__(self,tpm):\n",
        "        self.tpm = tpm\n",
        "        self.num_nodes = int(np.log2(len(tpm)))\n",
        "        \n",
        "    # Converts a list of states to a row number, so that we can index the tpm\n",
        "    # input : list of states, Ex. [0,1,0,0]\n",
        "    # output : row number based on little endian notation, so index zero in list is least\n",
        "    #          significant bit and index n-1 is most significant bit. Ex. [0,1,0,0] -> 2\n",
        "    def state_to_index(self,states):\n",
        "        decimal = 0\n",
        "        for i,state in enumerate(states):\n",
        "            decimal += (2**i) * (state)\n",
        "        return decimal\n",
        "    \n",
        "    # Converts a row number from the tpm into a list of states\n",
        "    # input : row number, total number of states. Ex. (2, 4)\n",
        "    # output : list of states that row number represents. Ex. (2, 4) -> [0,1,0,0]\n",
        "    #          We include the number of states so that we know how many zeros to append at the end.\n",
        "    def index_to_state(self,index,num_states):\n",
        "        binary = bin(index)[2:]\n",
        "        states = []\n",
        "        for state in binary: # convert row to binary\n",
        "            states.append(int(state))\n",
        "        \n",
        "        states = np.flip(states) # flip to make little endian\n",
        "       \n",
        "        if (len(states) < num_states): \n",
        "            states = np.concatenate((states,np.zeros((num_states-len(states)),dtype=int)))\n",
        "            \n",
        "        return states\n",
        "    \n",
        "    # Because they're conditional probability distributions, the rows need to sum to one\n",
        "    def normalize_rows(self,tpm):\n",
        "        return tpm/np.sum(tpm,1)[:, np.newaxis]\n",
        "    \n",
        "    # return the powerset of a list of nodes\n",
        "    def powerset(self,iterable):\n",
        "        \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
        "        s = list(iterable)\n",
        "        return chain.from_iterable(combinations(s, r) for r in range(1,len(s)+1))\n",
        "    \n",
        "    # returns the tensor product of two tpm (effect)\n",
        "    def tensor_product(self,t1,t2):\n",
        "        tensor_product = np.zeros((t1.shape[0],t1.shape[1]*t2.shape[1]))\n",
        "        row = 0\n",
        "        for c2 in t2.T:\n",
        "            for c1 in t1.T:\n",
        "                tensor_product[:,row] = c1*c2\n",
        "                row+=1\n",
        "                \n",
        "        return tensor_product\n",
        "        \n",
        "    \"\"\"\n",
        "    effect_repertoire :\n",
        "        input : mechanism (t nodes), purview (t+1 nodes)\n",
        "        algorithm : from original tpm find the tpm P(purview | mechanism)\n",
        "        output : repertoire for those nodes\n",
        "    \"\"\"    \n",
        "    def effect_repertoire(self,mechanism,purview):\n",
        "        # The effect repertoire captures the conditional transition probability of transitioning to each\n",
        "        # purview state, given the current mechanism state, so it needs to be of size\n",
        "        # NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE PURVIEW STATES, but we start by marginalizing\n",
        "        # over only the mechanism states, so NUMBER POSSIBLE MECHANISM STATES X NUMBER POSSIBLE STATES\n",
        "        mechanism_effect_repertoire = np.zeros((2**len(mechanism),2**self.num_nodes))\n",
        "        \n",
        "        # We marginalize over the mechanism states, which means we sum the probabilities of rows which\n",
        "        # only differ in the state of nodes not in the mechanism.\n",
        "        # We do this by finding the mechanism's state for a given row and mapping that row in the original tpm\n",
        "        # to the correct row in the new mechanism repertoire\n",
        "        for row in range(self.tpm.shape[0]):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            mechanism_effect_repertoire[self.state_to_index(mechanism_state),:] += self.tpm[row,:]\n",
        "        \n",
        "        # This is the final effect repertoire\n",
        "        effect_repertoire = np.zeros((2**len(mechanism),2**len(purview)))\n",
        "        \n",
        "        # Second, we marginalize over the column states, which means we sum the probabilities of columns which\n",
        "        # only differ in the state of nodes not in the purview.\n",
        "        # We do this by finding the purview's state for a given column and mapping that row in the original tpm\n",
        "        # to the correct column in the new effect repertoire\n",
        "        for column in range(self.tpm.shape[1]):\n",
        "            purview_state = self.index_to_state(column,self.num_nodes)[purview]\n",
        "            effect_repertoire[:,self.state_to_index(purview_state)] += mechanism_effect_repertoire[:,column]\n",
        "        \n",
        "        # All that's left to do is normalize the rows because each row is a conditional probability distribution\n",
        "        effect_repertoire = self.normalize_rows(effect_repertoire)\n",
        "        \n",
        "        # Now, we have to expand the effect_repertoire into the original state space which has all the \n",
        "        # possible current states at time t\n",
        "        expanded_effect_repertoire = np.zeros((2**self.num_nodes,2**len(purview)))\n",
        "        \n",
        "        # This is done by mapping distributions in the effect_repertoire to each row in the expanded repertoire\n",
        "        # where the mechanism's state matches\n",
        "        for row in range(2**self.num_nodes):\n",
        "            mechanism_state = self.index_to_state(row,self.num_nodes)[mechanism]\n",
        "            expanded_effect_repertoire[row,:] = effect_repertoire[self.state_to_index(mechanism_state),:]\n",
        "            \n",
        "        return expanded_effect_repertoire\n",
        "    \n",
        "    def effect_mip(self,system,purview):\n",
        "        pass\n",
        "        \"\"\"\n",
        "        for each possible partition of the pair (system + purview):\n",
        "            for each partitioned subset:\n",
        "                partitioned tpm = tensor multiply partitioned subset tpms \n",
        "                                    (effect_repertoire(part_system,part_purview))\n",
        "            calculate distance between partitioned tpm and effect_repertoire(system,purview)\n",
        "        return smallest distance\n",
        "        \"\"\"\n",
        "        \n",
        "    \n",
        "    \"\"\"\n",
        "    effect_mip : \n",
        "        input : system (t nodes) , purview (t+1 nodes)\n",
        "        \n",
        "        algorithm : for each possible partition of the pair (system + purview):\n",
        "                        for each partitioned subset:\n",
        "                            partitioned tpm = tensor multiply partitioned subset tpms \n",
        "                                                (effect_repertoire(part_system,part_purview))\n",
        "                        calculate distance between partitioned tpm and effect_repertoire(system,purview)\n",
        "                    return smallest distance\n",
        "                    \n",
        "        output : phi (distance between effect repertoire and minimum information partition repertoire)\n",
        "        \n",
        "    mie : \n",
        "        input : tpm for a specific system (in our case this is the entire system)\n",
        "        \n",
        "        algorithm : for each subset of nodes at t+1 of the system (call this a purview):\n",
        "                        call effect_mip(system, purview)\n",
        "                    return max effect_mip\n",
        "        \n",
        "        output : effect phi value\n",
        "                        \n",
        "        \n",
        "    concept :\n",
        "        input : list of nodes in system (in our case this will be the whole system)\n",
        "        \n",
        "        algorithm : min (mic(system),mie(system))\n",
        "        \n",
        "        output : phi value for that system\n",
        "    \"\"\"\n",
        "  \n",
        "    def cause_repertoire(self,tp,mechanism,purview,starting_states):\n",
        "\n",
        "        purview_cause_repertoire = np.zeros((2**len(purview),tp.shape[0]))\n",
        "\n",
        "        # marginalize out what is excluded from purview\n",
        "        for row in range(tp.shape[0]):\n",
        "            purview_state = self.index_to_state(row,self.num_nodes)[purview]\n",
        "            purview_cause_repertoire[self.state_to_index(purview_state)] += tp[row]\n",
        "\n",
        "        # normalize rows\n",
        "        for row in range(purview_cause_repertoire.shape[0]):\n",
        "            purview_cause_repertoire[row] = purview_cause_repertoire[row] / np.sum(purview_cause_repertoire[row])\n",
        "\n",
        "        mechanism_cause_repertoire = np.zeros((purview_cause_repertoire.shape[0],2**len(mechanism)))\n",
        "        \n",
        "        # marginalize out what is exluded from mechanism\n",
        "        for col in range(purview_cause_repertoire.shape[1]):\n",
        "            mechanism_state = self.index_to_state(col,self.num_nodes)[mechanism]\n",
        "            mechanism_cause_repertoire[:,self.state_to_index(mechanism_state)] += purview_cause_repertoire[:,col]\n",
        "        \n",
        "        # keep only the column of the curret state of the mechanism.\n",
        "        states = [starting_states[i] for i in mechanism]\n",
        "        index = self.state_to_index(states)\n",
        "        cause_repertoire = mechanism_cause_repertoire[:,index]\n",
        "\n",
        "        # normalize\n",
        "        cause_repertoire = cause_repertoire / np.sum(cause_repertoire)\n",
        "\n",
        "        # get the repertoire for all states not in the purview\n",
        "        # number of nodes in tp\n",
        "        num_not_in_purview = len(starting_states) - len(purview)\n",
        "        num_states = 2**num_not_in_purview\n",
        "        not_in_purview_repertoire = np.full((num_states),1/num_states)\n",
        "        \n",
        "        excluded_from_purview = set(range(len(starting_states))) - set(purview)\n",
        "\n",
        "        # multiply possibilities of cause_repertoire and things not in cause_repertoire\n",
        "        expanded_cause_repertoire_unsorted = np.array([])\n",
        "\n",
        "        for i in range(len(not_in_purview_repertoire)):\n",
        "            expanded_cause_repertoire_unsorted = np.append(expanded_cause_repertoire_unsorted,cause_repertoire * not_in_purview_repertoire[i])\n",
        "        \n",
        "        # make a copy of it\n",
        "        expanded_cause_repertoire = np.zeros((len(expanded_cause_repertoire_unsorted)))\n",
        "\n",
        "        # sort the copy\n",
        "        ordered = list(purview) + list(excluded_from_purview)\n",
        "        for i in range(len(expanded_cause_repertoire_unsorted)):\n",
        "            # make binary array\n",
        "            s = self.index_to_state(i,len(starting_states))\n",
        "            #re-order digits\n",
        "            reordered_s = np.full(len(s),9)\n",
        "            for j in range(len(ordered)):\n",
        "                reordered_s[j] = s[ordered[j]]\n",
        "            index = self.state_to_index(reordered_s)\n",
        "            expanded_cause_repertoire[i] = expanded_cause_repertoire_unsorted[index]\n",
        "            \n",
        "        return(expanded_cause_repertoire)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2FB4243AQRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53782d54-114d-4b50-b2f3-23bf43515bcb"
      },
      "source": [
        "test = phi(np.array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 1., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "                   [0., 0., 0., 0., 0., 0., 0., 1.],\n",
        "                   [0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "                   [0., 0., 0., 1., 0., 0., 0., 0.]], dtype=int))\n",
        "\n",
        "test.cause_repertoire(test.tpm,[2],[1,2],[1,1,0])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qmpYiU7Fc8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeX7sVypAQRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6e937b7e-eb8f-4464-b30e-e6f4fef7fdc2"
      },
      "source": [
        "test.tpm"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNPHOkUpAQRM",
        "colab_type": "code",
        "colab": {},
        "outputId": "f39cafd3-c3b7-4c39-fad5-f84b1fe58417"
      },
      "source": [
        "p1 = test.tensor_product(test.effect_repertoire([1,2],[0]),test.effect_repertoire([2],[1]))\n",
        "print (p1)\n",
        "test.tensor_product(p1,test.effect_repertoire([1],[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  0.  0.  0. ]\n",
            " [1.  0.  0.  0. ]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  1.  0.  0. ]\n",
            " [0.  0.5 0.  0.5]\n",
            " [0.  0.5 0.  0.5]\n",
            " [0.  0.5 0.  0.5]\n",
            " [0.  0.5 0.  0.5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  ],\n",
              "       [0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  ],\n",
              "       [0.  , 0.5 , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  ],\n",
              "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
              "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
              "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25],\n",
              "       [0.  , 0.25, 0.  , 0.25, 0.  , 0.25, 0.  , 0.25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LjRyD4gAQRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyuq3OzgAQRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}